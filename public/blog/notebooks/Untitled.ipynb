{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For my Machine Learing class at A&M, I implemented common ML algorithms from the ground up. It's amazing how easy it is to implement an ML technique in python. I thought that I'd share my implementations in a series of short blog posts. (I am new to python, so please cut me some slack.) In my opinion, there are three main advantages to this endeavour:\n",
    "\n",
    "- The understanding we get when we implement something from scratch is unmatched. A lot of the times, we think we understand a concept but when we implement it, we get a slew of doubts, thereby forcing us to really get the details right. \n",
    "- It helps us appreciate the design of libraries better and understand why things are designed a certain way. It helps truly get the API of a library with enduring success like scikit-learn.  \n",
    "- The satisfaction when we see the identical results convinces, that these libraries do not do something like the algorithm we study but actually implement the very algorithm we study, only better. \n",
    "\n",
    "\n",
    "# Techniques\n",
    "\n",
    "In this blog, I am sharing the code for \n",
    "\n",
    "1. A small module to scale training and testing dataset features, the right way.\n",
    "2. A K Nearest Neighbour classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (Libraries and Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this series of posts concentrates on the implementations, I won't delve into the data and results per se. I'll just briefly explain the dataset and the classification task for demonstration purposes. The dataset shows the response - area (in square feet) affected by volcanos and different features corresponding to it. We can change this to a classification problem by predicting whether the area was affected by volcanoes or not (area > 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area\n",
      "0  7  5      3    5  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0\n",
      "1  7  4     10    2  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0\n",
      "2  7  4     10    6  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0\n",
      "3  8  6      3    5  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0\n",
      "4  8  6      3    7  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0\n"
     ]
    }
   ],
   "source": [
    "df_train_org = pd.read_csv(\"../data/ml_scratch_1_train.csv\")\n",
    "df_test_org = pd.read_csv(\"../data/ml_scratch_1_test.csv\")\n",
    "print(df_train_org.head())\n",
    "\n",
    "tr_X = df_train_org.loc[:, df_train_org.columns != 'area']\n",
    "ts_X = df_test_org.loc[:, tr_X.columns]\n",
    "tr_y = (df_train_org['area'] > 0)*1\n",
    "ts_y = (df_test_org['area'] > 0)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knn():\n",
    "\n",
    "    \"\"\"A knn classifier \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 k:\"int\" = 3,\n",
    "                 norm:\"float\"=2.0 ,\n",
    "                 standardization=\"normalize\"):\n",
    "\n",
    "        self.k = k\n",
    "        self.norm = norm\n",
    "        self.standardization = standardization\n",
    "  \n",
    "\n",
    "    def fit(self, tr_X, tr_y):\n",
    "        \"\"\"Pass training data as X and y \"\"\"\n",
    "        self.standardizer = Standardize(X=tr_X)\n",
    "        self.tr_X = self.standardizer.standardize(method=self.standardization)\n",
    "        self.tr_y = tr_y\n",
    "\n",
    "\n",
    "    def predict(self, ts_X):\n",
    "        ts_X = self.standardizer.standardize(\n",
    "            method=self.standardization, X=ts_X)\n",
    "        d = self._dist_matrix(ts_X)\n",
    "        neighbours = self._get_nearest_neighbour_indices(d)\n",
    "        counts = self._count_votes(neighbours)\n",
    "        return self._tag_winner(counts)\n",
    "\n",
    "\n",
    "    def _dist_matrix(self, ts_X):\n",
    "        dists = scipy.spatial.distance_matrix(ts_X, self.tr_X, p=self.norm)\n",
    "        dists = np.vstack(dists)\n",
    "        return dists\n",
    "\n",
    "\n",
    "    def _calc_dist(self, vec):\n",
    "        rows = self.tr_X.shape[0]\n",
    "        dists = np.zeros(rows)\n",
    "        for i in range(rows):\n",
    "            tr_row = self.tr_X.iloc[i]\n",
    "            dist = 0\n",
    "            for j in range(len(tr_row)):\n",
    "                if isinstance(tr_row[j].dtype, int) and self.cat_hamming:\n",
    "                    dist += (tr_row[j] == vec[j])*1\n",
    "                else:\n",
    "                    dist += (abs(tr_row[j] - vec[j])**self.norm)\n",
    "            dists[i] = dist ** (1/self.norm)\n",
    "        return dists\n",
    "\n",
    "\n",
    "    def _get_nearest_neighbour_indices(self, dist_matrix):\n",
    "        return np.argpartition(dist_matrix, kth=self.k, axis=1)[:, :self.k]\n",
    "\n",
    "\n",
    "    def _count_votes(self, indice_matrix):\n",
    "        return np.apply_along_axis(lambda x: collections.Counter(self.tr_y.iloc[x]), 1, indice_matrix)\n",
    "\n",
    "\n",
    "    def _tag_winner(self, vote_mat):\n",
    "        count_max = np.vectorize(lambda x: x.most_common(1)[0][0])\n",
    "        return count_max(vote_mat)\n",
    "\n",
    "\n",
    "    def score(self, ts_X, ts_y):\n",
    "        return (ts_y == self.predict(ts_X)).mean()\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (f'Knn(k={self.k}, norm={self.norm}, standardization=\"{self.standardization}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
